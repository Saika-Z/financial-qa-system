'''
 # Author: Wenqing Zhao
 # Date: 2025-12-10 10:33:51
 # LastEditTime: 2025-12-10 10:52:08
 # Description: 
 # FilePath: /financial-qa-system/backend/data/raw/getCompanyNews.py
'''
from GoogleNews import GoogleNews
import pandas as pd
import os
from datetime import datetime, timedelta

def fetch_and_save_news(company, start_date, end_date, output_dir):
    """
    ä½¿ç”¨ GoogleNews åº“è·å–æŒ‡å®šå…¬å¸åœ¨æ—¶é—´èŒƒå›´å†…çš„æ–°é—»ï¼Œå¹¶ä¿å­˜ä¸º CSVã€‚
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # 1. åˆå§‹åŒ– GoogleNews å¯¹è±¡
    googlenews = GoogleNews()
    googlenews.setlang('en')  # è®¾ç½®è¯­è¨€ä¸ºè‹±æ–‡
    googlenews.setperiod('7d') # è®¾ç½®æœç´¢å‘¨æœŸ (è™½ç„¶è®¾ç½®äº†æ—¥æœŸèŒƒå›´ï¼Œä½†è¿™ä¸ªå‚æ•°æœ‰åŠ©äºé¿å…è¢«è®¤ä¸ºæ˜¯æœºå™¨äºº)
    googlenews.set_time_range(start_date, end_date)
    
    # 2. æ‰§è¡Œæœç´¢
    # æœç´¢æŸ¥è¯¢ï¼šå…¬å¸åç§° + "news" (å¯ä»¥ä¼˜åŒ–ä¸ºæ›´å…·ä½“çš„æŸ¥è¯¢)
    search_query = f'"{company}" news stock' 
    print(f"ğŸ”„ æ­£åœ¨æœç´¢æŸ¥è¯¢: {search_query}")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")

    googlenews.search(search_query)

    # 3. æŠ“å–æ‰€æœ‰é¡µé¢çš„ç»“æœ
    results = []
    # GoogleNews é»˜è®¤åªæŠ“å–ç¬¬ä¸€é¡µï¼Œéœ€è¦å¾ªç¯æŠ“å–æ›´å¤šé¡µé¢
    for page in range(1, 6): # å°è¯•æŠ“å–å‰ 5 é¡µ (æ¯é¡µçº¦ 10-15 æ¡æ–°é—»)
        # æ³¨æ„ï¼šgooglenews.get_page(page) æœ‰æ—¶å¯èƒ½è§¦å‘åçˆ¬æœºåˆ¶ï¼Œè°¨æ…ä½¿ç”¨
        try:
            googlenews.get_page(page)
            page_results = googlenews.results()
            if not page_results:
                print(f"âœ… ç¬¬ {page} é¡µæ²¡æœ‰æ›´å¤šç»“æœï¼Œåœæ­¢æœç´¢ã€‚")
                break
            results.extend(page_results)
            print(f"    - æˆåŠŸæŠ“å–ç¬¬ {page} é¡µï¼Œå½“å‰æ€»è®¡ {len(results)} æ¡æ–°é—»ã€‚")
        except Exception as e:
            print(f"âŒ æŠ“å–ç¬¬ {page} é¡µæ—¶å‘ç”Ÿé”™è¯¯æˆ–è§¦å‘åçˆ¬æœºåˆ¶: {e}")
            break
            
    # 4. è½¬æ¢å¹¶ä¿å­˜æ•°æ®
    if not results:
        print("âŒ æœªè·å–åˆ°ä»»ä½•æ–°é—»ç»“æœã€‚")
        return

    df = pd.DataFrame(results)
    
    # æ¸…ç†å¹¶ç­›é€‰å…³é”®åˆ—
    # å…³é”®åˆ—ï¼š['title', 'date', 'media', 'desc', 'link']
    # æ³¨æ„ï¼š'desc' æ˜¯æ–°é—»æ‘˜è¦ï¼Œ'link' æ˜¯æ–°é—»åŸæ–‡é“¾æ¥ï¼Œ'text' åˆ—å¯èƒ½åŒ…å«æ‘˜è¦æˆ–ç©ºå€¼
    if 'date' in df.columns:
        df = df.rename(columns={'date': 'published'})
    
    # ç¡®ä¿åªä¿ç•™ RAG è®­ç»ƒæœ‰ç”¨çš„åˆ—
    columns_to_keep = ['title', 'published', 'media', 'desc', 'link', 'datetime']
    df_clean = df[[col for col in columns_to_keep if col in df.columns]]
    
    # ç”Ÿæˆæ–‡ä»¶å
    file_name = f"{TICKER}_news_{START_DATE.replace('/', '-')}_to_{END_DATE.replace('/', '-')}.csv"
    file_path = os.path.join(output_dir, file_name)

    df_clean.to_csv(file_path, index=False, encoding='utf-8')
    print(f"\nğŸ‰ æˆåŠŸå°† {len(df_clean)} æ¡æ–°é—»æ•°æ®ä¿å­˜åˆ°ï¼š{file_path}")


if __name__ == "__main__":
    # --- é…ç½® ---
    TICKER = "AAPL"
    COMPANY_NAME = "Apple"  # ç”¨äºæœç´¢çš„å…¬å¸åç§°ï¼Œæ¯”è‚¡ç¥¨ä»£ç æ›´æœ‰æ•ˆ
    DOWNLOAD_DIR = "backend/data/raw/company_history_news"
    START_DATE = (datetime.now() - timedelta(days=365*2)).strftime("%m/%d/%Y")  # è¿‡å»ä¸¤å¹´
    END_DATE = datetime.now().strftime("%m/%d/%Y")
    # ----------
    # æ‰§è¡Œå‡½æ•°
    fetch_and_save_news(COMPANY_NAME, START_DATE, END_DATE, DOWNLOAD_DIR)